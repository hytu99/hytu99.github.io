<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="水远，怎知流水外，却是乱山尤远。"><title>【论文阅读】Deep Code Search | 山尤远</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">【论文阅读】Deep Code Search</h1><a id="logo" href="/.">山尤远</a><p class="description">THY’s Blog</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">【论文阅读】Deep Code Search</h1><div class="post-meta">Oct 6, 2019<span> | </span><span class="category"><a href="/categories/Paper-Reading/">Paper Reading</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 726</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 4</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-Code-Search"><span class="toc-text">Deep Code Search</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ABSTRACT"><span class="toc-text">ABSTRACT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-INTRODUCTION"><span class="toc-text">1.  INTRODUCTION</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-BACKGROUND"><span class="toc-text">2.  BACKGROUND</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-A-DEEP-NEURAL-NETWORK-FOR-CODE-SEARCH"><span class="toc-text">3.  A DEEP NEURAL NETWORK FOR CODE SEARCH</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-DEEPCS-DEEP-LEARNING-BASED-CODE-SEARCH"><span class="toc-text">4.  DEEPCS: DEEP LEARNING BASED CODE SEARCH</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-EVALUATION"><span class="toc-text">5.  EVALUATION</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-DISCUSSION"><span class="toc-text">6.  DISCUSSION</span></a></li></ol></li></ol></div></div><div class="post-content"><blockquote>
<p>【ASE高级软件工程】第二次结对作业Code Search论文阅读笔记</p>
</blockquote>
<h2 id="Deep-Code-Search"><a href="#Deep-Code-Search" class="headerlink" title="Deep Code Search"></a>Deep Code Search</h2><h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><ul>
<li><p>we propose a novel deep neural network named <strong>CODEnn</strong>（Code-Description Embedding Neural Network）.</p>
</li>
<li><p>CODEnn jointly embeds code snippets and natural language descriptions into a high-dimensional vector space.</p>
</li>
<li><p>we implement a code search tool named <strong>DeepCS</strong>. </p>
</li>
</ul>
<h3 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1.  INTRODUCTION"></a>1.  INTRODUCTION</h3><p><strong>Other Approaches:</strong>  </p>
<ul>
<li><p>information retrieval（IR）techniques.</p>
</li>
<li><p>problem: mismatch between the high-level intent reﬂected in the natural language queries and low-level implementation details in the source code.</p>
</li>
</ul>
<p><strong>Our Method:</strong></p>
<ul>
<li><p>CODEnn jointly embeds code snippets and natural language descriptions into a high-dimensional vector space</p>
</li>
<li><p>DeepCS trains the CODEnn model on a corpus of 18.2 million Java code snippets（in the form of commented methods）from GitHub.   </p>
</li>
<li><p>DeepCS reads code snippets from a codebase and embeds them into vectors using the trained CODEnn.</p>
</li>
<li><p>when a user query arrives, DeepCS fnds code snippets that have the nearest vectors to the query vector and return them. </p>
</li>
</ul>
<p><strong>Evalutate:</strong></p>
<ul>
<li>we perform code search on a search codebase using 50 real-world queries obtained from Stack Overﬂow.  </li>
</ul>
<h3 id="2-BACKGROUND"><a href="#2-BACKGROUND" class="headerlink" title="2.  BACKGROUND"></a>2.  BACKGROUND</h3><p><strong>Embedding:</strong> a technique for learning vector representations of entities.</p>
<p><strong>Word Embedding:</strong> It represents words as fixed-length vectors so that similar words are close<br>to each other in the vector space.</p>
<p><strong>Sequence Embedding:</strong> Use RNN. The embedding vector of the sentence is summarized from the hidden states $h_1, …, h_T$（select the last state or use maxpooling）. </p>
<p><strong>Joint Embedding:</strong> a technique to jointly embed/correlate heterogeneous data into a unifed vector space so that semantically similar concepts across the two modalities occupy nearby regions of the space.<br>$$<br>\cal{X}\xrightarrow{\phi}\it{V}_\cal{X}\rightarrow \it{J}(\it{V}_\cal{X},\it{V}_\cal{Y})\leftarrow \it{V}_\cal{Y} \xleftarrow{\psi}\cal{Y}<br>$$<br><img src="joint-embeding.png" alt="An example of joint embedding"></p>
<h3 id="3-A-DEEP-NEURAL-NETWORK-FOR-CODE-SEARCH"><a href="#3-A-DEEP-NEURAL-NETWORK-FOR-CODE-SEARCH" class="headerlink" title="3.  A DEEP NEURAL NETWORK FOR CODE SEARCH"></a>3.  A DEEP NEURAL NETWORK FOR CODE SEARCH</h3><p><img src="CODEnn.png" alt="The structrue of CODEnn"></p>
<p><strong>Architecture:</strong></p>
<ul>
<li><p>Code Embedding Network: It embeds source code into vectors.（Three parts: the method name, the API invocation sequence, and the tokens contained in the source code）</p>
</li>
<li><p>Description Embedding Network: It embeds natural language descriptions into<br>vectors. </p>
</li>
<li><p>Similarity Module: cosine similarity.</p>
</li>
</ul>
<p><strong>Training:</strong></p>
<ul>
<li><p>Training Instance: $\langle C, D+, D-\rangle$. D+ is a postitive description of code snippet C. D- is a negtive description of C(chosen randomly). </p>
</li>
<li><p>Loss: $\cal{L}(\theta) = \sum\limits_{\langle C, D+, D-\rangle \in P} max(0, \epsilon - cos(\mathbf{c}, \mathbf{d+})+cos(\mathbf{c}, \mathbf{d-})) $</p>
</li>
</ul>
<h3 id="4-DEEPCS-DEEP-LEARNING-BASED-CODE-SEARCH"><a href="#4-DEEPCS-DEEP-LEARNING-BASED-CODE-SEARCH" class="headerlink" title="4.  DEEPCS: DEEP LEARNING BASED CODE SEARCH"></a>4.  DEEPCS: DEEP LEARNING BASED CODE SEARCH</h3><p><strong>Extracion:</strong> </p>
<p><img src="extraction.png" alt="An example of extracting code elements"></p>
<p>We build the training tuples using Java methods that have documentation comments from open-source projects on GitHub.</p>
<p><strong>Training and Searching:</strong></p>
<p><img src="workflow.png" alt="The overall workflow of DeepCS"></p>
<h3 id="5-EVALUATION"><a href="#5-EVALUATION" class="headerlink" title="5.  EVALUATION"></a>5.  EVALUATION</h3><p><strong>Search Codebase:</strong> </p>
<p>Search codebase is different from the training corpus. They are considered in isolation and contain all code（including those do not have Javadoc comments）.</p>
<p><strong>Performance Measure:</strong></p>
<ul>
<li>FRank: the rank of the first hit result in the result list.</li>
<li>SuccessRate@k: percentage of queries for which more than one correct<br>result could exist in the top k ranked results（$\frac{1}{|Q|}\sum\limits_{q=1}^{|Q|} \delta(FRank_q \leq k)$）.</li>
<li>Precision@k: percentage of relevant results in the top k returned results for each query.</li>
<li>MRR：the average of the reciprocal ranks of results of a set of queries（$\frac{1}{|Q|}\sum\limits_{q=1}^{|Q|} \frac{1}{FRank_q}$）.</li>
</ul>
<p><strong>Results:</strong></p>
<img src="The statistical comparison.png" alt="The statistical comparison" style="zoom:67%;">

<p>The symbol ‘+’ indicates the average value.</p>
<img src="accuracy.png" alt="Overall Accuracy" style="zoom:67%;">

<h3 id="6-DISCUSSION"><a href="#6-DISCUSSION" class="headerlink" title="6.  DISCUSSION"></a>6.  DISCUSSION</h3><p><strong>Strengths:</strong></p>
<ul>
<li>It has the ability to recognize query semantics (e.g., <em>queue an event to be run on the thread*​ and *run an event on a thread queue</em>)</li>
<li>Its search results are less affected by irrevant or noisy keyword (e.g., <em>get the content<br>of an input stream as a string using a specified character encoding</em>).</li>
<li>it not only seeks snippets with matched keywords but also recommends those without matched keywords but are semantically related.</li>
</ul>
<p><strong>Why does DeepCS Work?</strong></p>
<ul>
<li>A unifed representation of heterogeneous data.</li>
<li>Better query understanding through deep learning.</li>
<li>Clustering snippets by natural language semantics.</li>
</ul>
<p><strong>Limitation:</strong></p>
<p>It sometimes ranks partially relevant results higher than the exact matching ones. This<br>is because DeepCS ranks results by just considering their semantic vectors.</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></div><iframe src="/donate/?AliPayQR=/img/AliPayQR.jpg&amp;WeChatQR=/img/WeChatQR.png&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="http://hytu99.github.io/deep-code-search/" data-id="ck7ifmghe000k7gu79v4kg18t" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAAByElEQVR42u3aS47CMBAFQO5/aWaLNCK818YGpPIKkRBXWLT649stXveH9fjNs3v+X332zNuOhYuLu8y9X65n3Ovfti+cGHBxcc9zrwNN+3n2d0TBDhcX90e4xWZxwoSLi/tb3CS5aYsfXFzc7+SubL+S6Gys1XBxcRe4eZdy3+ct/V1cXNwR916u69Ilf8Jwd1xc3CPctlBZSUTyZsp1AwUXF/dT3KQESsJZ8vxk4PqiU4KLi7uBmweXPN2ZHdEo7sfFxT3OTbZfGYfMyi1cXNyT3JXjFEnLo02biuIHFxd3AzcfeORjj3c1TaIQhouLu42bh61Z87Q90vH0z8LFxT3IzZOVdw1T2/EJLi7uSe67DmbNUqXZN7i4uGe47cgzaaEuhaHrNAsXF/cgtz1KtTIuzVsnL/q7uLi4m7n5qGNlyxkRFxf3U9y2NsoHq22i8+JOXFzczdxZCpK3R5NRStGnwcXFPcJt2xPtOLYtrtp9cXFx93Hz4DV7sbwoiq7i4uIe5LaBph2o5K9d1Gq4uLhfw81bqHm5VeRfuLi4X8lNmh2zpKcepeDi4m7mtk3S2cGLthGDi4v7Ke5s8HkmMVrq7+Li4k64fzrwKfjA9IyhAAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/code-search/">code search</a><a href="/tags/deep-learning/">deep learning</a><a href="/tags/nlp/">nlp</a></div><div class="post-nav"><a class="pre" href="/ml-linear-regression/">【机器学习笔记】1. Linear Regression</a><a class="next" href="/code-template/">机试模板整理</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: '369b643e56617e4a3536',
  clientSecret: '857e355d82af9a690de1fa191c7600e8db09e80c',
  repo: 'https://github.com/hytu99/hytu99.github.io.git',
  owner: 'hytu99',
  admin: ['hytu99'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Paper-Reading/">Paper Reading</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术总结/">技术总结</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/程序设计/">程序设计</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/编程/" style="font-size: 15px;">编程</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/学习笔记/" style="font-size: 15px;">学习笔记</a> <a href="/tags/保研/" style="font-size: 15px;">保研</a> <a href="/tags/机试/" style="font-size: 15px;">机试</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/code-search/" style="font-size: 15px;">code search</a> <a href="/tags/deep-learning/" style="font-size: 15px;">deep learning</a> <a href="/tags/nlp/" style="font-size: 15px;">nlp</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/ml-svm/">【机器学习笔记】4. Support Vector Machine & Lagrange Duality</a></li><li class="post-list-item"><a class="post-list-link" href="/ml-naive-bayes/">【机器学习笔记】3. Naive Bayes & Logistic Regression</a></li><li class="post-list-item"><a class="post-list-link" href="/docker/">Docker入门总结</a></li><li class="post-list-item"><a class="post-list-link" href="/ml-gradient-descent/">【机器学习笔记】2. Gradient Descent</a></li><li class="post-list-item"><a class="post-list-link" href="/ml-linear-regression/">【机器学习笔记】1. Linear Regression</a></li><li class="post-list-item"><a class="post-list-link" href="/deep-code-search/">【论文阅读】Deep Code Search</a></li><li class="post-list-item"><a class="post-list-link" href="/code-template/">机试模板整理</a></li><li class="post-list-item"><a class="post-list-link" href="/first-article/">终于弄好博客啦</a></li><li class="post-list-item"><a class="post-list-link" href="/hello-world/">Hello World</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">山尤远.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a><span style="font-size:14px;" id="busuanzi_container_site_pv"><br> 本站总访问量  <span rel="nofollow" id="busuanzi_value_site_pv"></span> 人次,</span><span style="font-size:14px;" id="busuanzi_container_site_uv"> 访客数  <span rel="nofollow" style="font-size:14px;" id="busuanzi_value_site_uv"></span> 人.</span></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>